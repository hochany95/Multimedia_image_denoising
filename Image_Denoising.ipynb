{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Denoising.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hochany95/Multimedia_image_denoising/blob/main/Image_Denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mIA_oSkbDpi"
      },
      "source": [
        "# Dataset Upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua7uuvXNbHq3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdaWcyrRarWj"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "file_name = 'Multimedia_dataset.zip'\n",
        "zip_path = \"/content/drive/MyDrive/Multimedia_dataset.zip\"\n",
        "\n",
        "print(file_name)\n",
        "\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q \"{file_name}\"\n",
        "!rm \"{file_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAQ_5dFcbu--"
      },
      "source": [
        "import os \n",
        "\n",
        "print(len(os.listdir('./train')))\n",
        "print(len(os.listdir('./validation')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q-ecc-Zcg-0"
      },
      "source": [
        "import torch\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "root_path = '/content/'# 동일안 root??\n",
        "\n",
        "train_root = './train'\n",
        "val_root = './validation'\n",
        "\n",
        "train_examples = os.listdir(train_root)\n",
        "val_examples = os.listdir(val_root)\n",
        "\n",
        "print(\"train_len: \", len(train_examples))\n",
        "print(\"validation len: \", len(val_examples))\n",
        "\n",
        "img = plt.imread(train_root+'/'+train_examples[0])\n",
        "print(img.shape)\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43w6sCM5dXAG"
      },
      "source": [
        "# Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikug9AUTda-e"
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"Using device: \", DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL-B6lcLvyW8"
      },
      "source": [
        "# Noise Tranform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr3lv7mrv3Y9"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "import random\n",
        "\n",
        "class NoiseTransform(object):\n",
        "  def __init__(self, size=256, mode=\"training\"):\n",
        "    super(NoiseTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "  \n",
        "  def gaussian_noise(self, img):\n",
        "    mean = 0\n",
        "    stddev = 25\n",
        "    noise = Variable(torch.zeros(img.size()))\n",
        "    noise = noise.data.normal_(mean, stddev/255.)\n",
        "\n",
        "    return noise\n",
        "\n",
        "  def __call__(self, img):\n",
        "    if (self.mode == \"training\") | (self.mode == \"validation\"):\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor()])\n",
        "      self.noise_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(self.gaussian_noise),\n",
        "      ])\n",
        "      return self.gt_transform(img), self.noise_transform(img)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.ToTensor()])\n",
        "      return self.gt_transform(img)\n",
        "    else:\n",
        "      print(\"[Noise transform]: mode error\")\n",
        "      return NotImplementedError\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPZ0DLzzrXg"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aESDiM77hv2Y"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage\n",
        "from PIL import Image \n",
        "\n",
        "def image_show(img):\n",
        "  if isinstance(img, torch.Tensor):\n",
        "    img = ToPILImage()(img)\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "class DenoisingDataSet(data.Dataset):\n",
        "  def __init__(self, root_path, size=256):\n",
        "    super(DenoisingDataSet, self).__init__()\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.examples = [file_name for file_name in os.listdir(self.root_path)]\n",
        "    # root를 모를 경우? \n",
        "    self.transforms = None\n",
        "  \n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = NoiseTransform(self.size, mode)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.examples[idx]\n",
        "\n",
        "    # img = plt.imread(os.path.join(self.root_path, file_name))\n",
        "    # #예제 / \n",
        "    img = Image.open(os.path.join(self.root_path, file_name))\n",
        "    \n",
        "    if self.mode == \"testing\":\n",
        "      input_img = self.transforms(img)\n",
        "      sample = {'img':input_img, 'file_name':file_name}\n",
        "    else:\n",
        "      clean, noise = self.transforms(img)\n",
        "      sample = {'img':clean, 'noise':noise, 'file_name':file_name}\n",
        "    \n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UrZOOHR7UL"
      },
      "source": [
        "# Data loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB-ssEVh32jR"
      },
      "source": [
        "import tqdm \n",
        "import torch.utils.data as data\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_root = './train'\n",
        "val_root = './validation'\n",
        "\n",
        "train_dataset = DenoisingDataSet(train_root, 256) #root, size\n",
        "train_dataset.set_mode('training')\n",
        "\n",
        "val_dataset = DenoisingDataSet(val_root, 256)\n",
        "val_dataset.set_mode('validation')\n",
        "\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size = BATCH_SIZE, \n",
        "    shuffle = True,\n",
        "    num_workers = 2, \n",
        "    drop_last = True\n",
        ")\n",
        "val_dataloader = data.DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size = BATCH_SIZE, \n",
        "    shuffle = False,\n",
        "    num_workers = 2,\n",
        "    drop_last = True\n",
        ")\n",
        "\n",
        "\n",
        "# for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "#   img = data[\"img\"]\n",
        "#   noise = data[\"noise\"]\n",
        "#   model_input = img + noise\n",
        "#   noise_image = torch.clamp(model_input, 0, 1)\n",
        "\n",
        "#   print(i, len(img),len(noise), len(noise_image))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-_1kaUYuTaT"
      },
      "source": [
        "# Network Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nbl44XJYA09"
      },
      "source": [
        "import re\n",
        "import os, glob, datetime, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.loss import _Loss\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "  def __init__(self, depth=17, n_channels=16, image_channels=3, use_bnorm=True, kernel_size=3):\n",
        "    super(DnCNN, self).__init__()\n",
        "    kernel_size = 3\n",
        "    padding = 1\n",
        "    layers = []\n",
        "\n",
        "    layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
        "    layers.append(nn.ReLU(inplace=True))\n",
        "    for _ in range(depth-2):\n",
        "      layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "      layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.95))\n",
        "      layers.append(nn.ReLU(inplace=True))\n",
        "    layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "    self.dncnn = nn.Sequential(*layers)\n",
        "    self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = x\n",
        "    out = self.dncnn(x)\n",
        "    return y - out\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        init.orthogonal_(m.weight)        \n",
        "        if m.bias is not None:\n",
        "          init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "          init.constant_(m.weight, 1)\n",
        "          init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btHc9ITEurzw"
      },
      "source": [
        "class sum_squared_error(_Loss):\n",
        "  def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
        "      super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
        "\n",
        "  def forward(self, input, target):\n",
        "      # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
        "      return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gueR8MK-uM4i"
      },
      "source": [
        "# Training session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W5_sbb_Clut"
      },
      "source": [
        "import torch, gc \n",
        "def free_cuda():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_etfmN3-uHo1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import numpy as np\n",
        "\n",
        "net = DnCNN().cuda()\n",
        "criterion = sum_squared_error()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 1e-3)\n",
        "\n",
        "train_info = []\n",
        "val_info = []\n",
        "EPOCH = 30\n",
        "\n",
        "save_path = './DenoisingNetwork'\n",
        "os.makedirs(save_path, exist_ok = True)\n",
        "output_path = os.path.join(save_path, 'denoising_model.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPDMsecsaO5Q"
      },
      "source": [
        "# 1epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZxzKTwFXs8F"
      },
      "source": [
        "def train_1epoch(net, train_dataloader):  \n",
        "  total_loss = 0\n",
        "  iteration = 0\n",
        "  net.train()\n",
        "  for step ,sample in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "    img = sample['img']\n",
        "    noise = sample['noise']\n",
        "    model_input = img + noise\n",
        "    noise_image = torch.clamp(model_input, 0, 1)    \n",
        "    noise_image = noise_image.float().cuda()\n",
        "    img = img.float().cuda()    \n",
        "    denoised = net(noise_image)\n",
        "\n",
        "    if denoised.size() != img.size():\n",
        "      print(\"다른 크기\",denoised.size(), img.size(), sample['file_name'])\n",
        "      continue\n",
        "    \n",
        "    loss = criterion(denoised, img)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "    iteration += 1  \n",
        "      \n",
        "  return total_loss / len(train_dataloader)\n",
        "\n",
        "def validation_1epoch(net, val_dataloader):\n",
        "  total_loss = 0\n",
        "  iteration = 0\n",
        "  net.eval()\n",
        "  for step ,sample in enumerate(tqdm.tqdm(val_dataloader)):\n",
        "    img = sample['img']\n",
        "    noise = sample['noise']\n",
        "    model_input = img + noise\n",
        "    noise_image = torch.clamp(model_input, 0, 1)    \n",
        "    noise_image = noise_image.float().cuda()\n",
        "    img = img.float().cuda()\n",
        "    denoised = net(noise_image)\n",
        "    if denoised.size() != img.size():\n",
        "      print(\"다른 크기\",denoised.size(), img.size(), sample['file_name'])      \n",
        "      continue\n",
        "\n",
        "    loss = criterion(denoised, img)\n",
        "    total_loss += loss.item()\n",
        "    iteration += 1  \n",
        "      \n",
        "  return total_loss / len(val_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25YE6mrOacuH"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0LDpuqkQWW0"
      },
      "source": [
        "low_loss = float('inf')\n",
        "for epoch in range(EPOCH):\n",
        "  print(\"{} EPOCH\".format(epoch))\n",
        "  train_loss = train_1epoch(net, train_dataloader)\n",
        "  if (epoch % 10 == 0):\n",
        "    print('epoch: {} loss: {}'.format(epoch+1, train_loss))\n",
        "  train_info.append({'loss':train_loss})\n",
        "\n",
        "  with torch.no_grad():\n",
        "    val_loss = validation_1epoch(net, val_dataloader)\n",
        "    val_info.append({'loss':val_loss})\n",
        "    if val_loss < low_loss:\n",
        "      low_loss = val_loss\n",
        "      torch.save({\n",
        "        'memo':'DenoisingDnCnnModel', \n",
        "        'loss':low_loss, \n",
        "        'model_weight':net.state_dict()\n",
        "      }, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpmqufc0a2I_"
      },
      "source": [
        "# loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYnLq_aCSlLW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "epoch_axis = np.arange(0, EPOCH)\n",
        "print(len(train_info), len(val_info))\n",
        "min_count = min(len(val_info), len(train_info))\n",
        "plt.title('LOSS')\n",
        "plt.plot(epoch_axis, [info['loss'] for info in train_info[:min_count]], epoch_axis, [info['loss'] for info in val_info[:min_count]], 'r-')\n",
        "plt.legend(['TRAIN', 'VALIDATION'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kpKjTCHFtRE"
      },
      "source": [
        "# Test session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qw47viiFu8w"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def transImage(img):\n",
        "  if isinstance(img, torch.Tensor):\n",
        "    return ToPILImage(img)\n",
        "  else:\n",
        "    return img\n",
        "free_cuda()\n",
        "for step ,sample in enumerate(val_dataloader):\n",
        "    original = sample['img']\n",
        "    noise = sample['noise']\n",
        "    model_input = original + noise\n",
        "    noised = torch.clamp(model_input, 0, 1)    \n",
        "    noised = noised.float().cuda()\n",
        "    image_show(noised[step])\n",
        "    original = original.float()\n",
        "\n",
        "    denoised = net(noised).cuda()\n",
        "    image_show(denoised[step])\n",
        "\n",
        "    if step == 2:\n",
        "      break\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}